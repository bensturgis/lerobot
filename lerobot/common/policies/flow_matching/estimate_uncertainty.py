import torch

from abc import ABC, abstractmethod
from pathlib import Path
from torch import nn, Tensor
from torch.distributions import Independent, Normal
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Tuple, Union

from lerobot.common.policies.flow_matching.configuration_flow_matching import FlowMatchingConfig
from lerobot.common.policies.flow_matching.configuration_uncertainty_sampler import (
    ComposedSequenceSamplerConfig,
    CrossEnsembleSamplerConfig,
    CrossLaplaceSamplerConfig,
    LikSamplerConfig,
    EpsilonBallSamplerConfig,
)
from lerobot.common.policies.flow_matching.laplace_utils import (
    draw_laplace_flow_matching_model,
    get_laplace_posterior
)
from lerobot.common.policies.flow_matching.ode_solver import ODESolver
from lerobot.common.policies.utils import get_device_from_parameters, get_dtype_from_parameters


class FlowMatchingUncertaintySampler(ABC):
    """
    Abstract base class for uncertainty samplers that sample multiple action sequences
    and their per-sample uncertainty based on a Flow Matching model.
    """
    def __init__(
        self,
        flow_matching_cfg: FlowMatchingConfig,
        velocity_model: nn.Module,
        num_action_seq_samples: int,
        generator: Optional[torch.Generator] = None,
    ):
        """
        Args:
            flow_matching_cfg: Shared configuration object for Flow Matching settings.
            velocity_model: The learned flow matching velocity model.
            num_action_seq_samples: How many action sequences and corresponding
                uncertainty scores to sample.
        """
        self.flow_matching_cfg = flow_matching_cfg
        self.velocity_model = velocity_model
        self.sampling_ode_solver = ODESolver(velocity_model)
        self.num_action_seq_samples = num_action_seq_samples
        self.generator = generator
        self.horizon = self.flow_matching_cfg.horizon
        self.action_dim = self.flow_matching_cfg.action_feature.shape[0]
        self.device = get_device_from_parameters(velocity_model)
        self.dtype = get_dtype_from_parameters(velocity_model)
        # Noise distribution is an isotropic Gaussian
        self.gaussian_log_density = Independent(
            Normal(
                loc = torch.zeros(self.horizon, self.action_dim, device=self.device),
                scale = torch.ones(self.horizon, self.action_dim, device=self.device),
            ),
            reinterpreted_batch_ndims=2
        ).log_prob
        # Store latest sampled action sequences and their uncertainty scores for logging
        self.latest_action_candidates = None
        self.latest_uncertainties = None

    def _prepare_conditioning(self, global_cond: Tensor) -> Tensor:
        """
        Reshape single global conditioning vector to (num_action_seq_samples, cond_dim).
        """
        if global_cond.ndim == 1:
            global_cond = global_cond.unsqueeze(0)
        if global_cond.ndim != 2 or global_cond.size(0) != 1:
            raise ValueError(
                f"Expected `global_cond` to contain exactly one feature vector "
                f"(shape (cond_dim,) or (1,cond_dim)), but got shape {tuple(global_cond.shape)}"
            )
        # repeat batch‐dim
        return global_cond.repeat(self.num_action_seq_samples, 1)

    @abstractmethod
    def conditional_sample_with_uncertainty(
        self,
        global_cond: Tensor,
    ) -> Tuple[Tensor, Tensor]:
        """
        Sample `num_action_seq_samples` many action sequences and compute their
        uncertainty score according to some specific metric.

        Args:
            global_cond: Single conditioning feature vector for the velocity
                model. Shape: [cond_dim,] or [1, cond_dim].

        Returns:
            - Action sequences samples. Shape: [num_action_seq_samples, horizon, action_dim].
            - Uncertainty scores. Shape: [num_action_seq_samples,]
        """
        pass

    def score_sample(
        self,
        scoring_metric: str,
        scorer_velocity_model: nn.Module,
        scorer_global_cond: Tensor,
        ode_states: Tensor,
        time_grid: Tensor,
        sampler_global_cond: Tensor,
        exact_divergence: bool,
    ) -> Tensor:
        """
        Compute an uncertainty score for a batch of action sequence samples
        generated by the sampler flow-matching model using a scorer flow matching
        model.

        Args:
            scoring_metric: Choice of scoring metric:
                - "intermediate_vel_norm": For all passed intermediate ODE states, evaluate
                the scorer's velocity field and compute the average L2 norm.
                - "terminal_vel_norm": Evaluate the scorer velocity only on the final sampled
                action sequence but at several times close to t=1 and compute the average L2 norm.
                - "intermediate_vel_diff": At each intermediate state compare the sampler and scorer
                velocities, ||v_sampler(x_t) - v_scorer(x_t)||, and average them.
                - "likelihood": Run a reverse-time ODE under the scorer model to compute the log-
                likelihood of the final sample; the score is the negative log-likelihood.
            scorer_velocity_model: Flow matching velocity model to compute the velocities field for
                scoring.
            scorer_global_cond: Conditioning vector used for the scorer model.
                Shape: (batch_size, cond_dim).
            ode_states: States produced by the forward ODE solver. Shape: (len(time_grid), batch_size,
            horizon, action_dim).
            time_grid: Times of integration evaluation points matching 'ode_states'.
            sampler_global_cond: Conditioning vector that was used for the sampler's velocity model.
                Needed for "intermediate_vel_diff".
            exact_divergence: Whether to compute exact divergence in the reverse-time ODE.
                Needed for "likelihood".

        Returns:
            Uncertainty scores per sample where larger values indicate higher uncertainty.
            Shape: (batch_size,).
        """
        # Compute uncertainty based on selected metric
        if scoring_metric == "intermediate_vel_norm":
            # Evaluate velocity field at each intermediate time point under scorer
            per_step_vel_norms = []
            for time, noisy_action_seq in zip(time_grid[1:-1], ode_states[1:-1]):
                time_batch = torch.full(
                    (ode_states[-1].shape[0],), time, device=self.device, dtype=self.dtype
                )
                velocity = scorer_velocity_model(
                    noisy_action_seq,
                    time_batch,
                    scorer_global_cond,
                )
                # L2 norm across time and action dims gives per-sample velocity magnitude
                per_step_vel_norms.append(torch.norm(velocity, dim=(1, 2)))
            
            # Use average velocity norm as uncertainty score
            return torch.stack(per_step_vel_norms, dim=0).mean(dim=0)
        elif scoring_metric == "terminal_vel_norm":
            # The sampled action sequence corresponds to the final state of the ODE
            sampled_action_seq = ode_states[-1]
            # Evaluate velocity on the final sampled sequence at times close to t=1
            terminal_vel_norms = []
            for time in time_grid[1:-1]:
                time_batch = torch.full(
                    (sampled_action_seq.shape[0],), time, device=self.device, dtype=self.dtype
                )
                velocity = scorer_velocity_model(
                    sampled_action_seq,
                    time_batch,
                    scorer_global_cond,
                )
                # L2 norm across time and action dims gives velocity magnitude
                terminal_vel_norms.append(torch.norm(velocity, dim=(1, 2)))

            # Use average velocity norm as uncertainty score 
            return torch.stack(terminal_vel_norms, dim=0).mean(dim=0)
        elif scoring_metric == "intermediate_vel_diff":
            # Evaluate difference between sampler and scorer velocity field at each
            # intermediate time point
            per_step_vel_diff: List[Tensor] = []
            for time, intermediate_state in zip(time_grid[1:-1], ode_states[1:-1]):
                time_batch = torch.full(
                    (ode_states[-1].shape[0],), time, device=self.device, dtype=self.dtype
                )
                sampler_velocity = self.velocity_model(
                    intermediate_state,
                    time_batch,
                    sampler_global_cond,
                )
                scorer_velocity = scorer_velocity_model(
                    intermediate_state,
                    time_batch,
                    scorer_global_cond,
                )
                velocity_difference = sampler_velocity - scorer_velocity
                # L2 norm across time and action dims gives magnitude of velocity difference
                per_step_vel_diff.append(torch.norm(velocity_difference, dim=(1, 2)))
            
            # Use average velocity difference as uncertainty score
            return torch.stack(per_step_vel_diff, dim=0).mean(dim=0)
        elif scoring_metric == "likelihood":            
            # Compute log-likelihood of sampled action sequences in scorer model    
            scoring_ode_solver = ODESolver(scorer_velocity_model)
            _, log_probs = scoring_ode_solver.sample_with_log_likelihood(
                x_init=ode_states[-1],
                time_grid=torch.tensor([1.0, 0.0], device=self.device, dtype=self.dtype),
                global_cond=scorer_global_cond,
                log_p_0 = self.gaussian_log_density,
                method=self.flow_matching_cfg.ode_solver_method,
                step_size=self.flow_matching_cfg.ode_step_size,
                atol=self.flow_matching_cfg.atol,
                rtol=self.flow_matching_cfg.rtol,
                exact_divergence=exact_divergence,
                generator=self.generator,
            )

            # Use negative log-likelihood as uncertainty score
            return -log_probs
        else:
            raise ValueError(
                f"Unsupported scoring_metric '{scoring_metric}'. "
                "Expected one of: 'intermediate_vel_norm', 'terminal_vel_norm', "
                "'intermediate_vel_diff', 'likelihood'."
            )


class CrossLaplaceSampler(FlowMatchingUncertaintySampler):
    """
    Estimates epistemic uncertainty of flow matching model by fitting a Laplace 
    approximation to a subset of weights. Action sequences are sampled from the MAP
    model and scored using models sampled from the Laplace posterior.

    The Laplace approximation is fit to the final layers of the velocity and/or image encoder.
    """
    def __init__(
        self,
        flow_matching_cfg: FlowMatchingConfig,
        cfg: CrossLaplaceSamplerConfig,
        flow_matching_model: nn.Module,
        laplace_calib_loader: DataLoader,
        laplace_path: Union[str, Path],
        generator: Optional[torch.Generator] = None,
    ):
        """
        Args:
            cfg: Sampler-specific settings.
            flow_matching_model: The full flow matching model including velocity and RGB encoder.
            laplace_calib_loader: DataLoader providing samples for fitting the Laplace
                approximation.
            laplace_path: Path to save or load the Laplace posterior.
        """
        # Use the MAP velocity network for sampling action sequences
        self.flow_matching_model = flow_matching_model
        velocity_model = self.flow_matching_model.unet
        super().__init__(
            flow_matching_cfg=flow_matching_cfg,
            velocity_model=velocity_model,
            num_action_seq_samples=cfg.num_action_seq_samples,
            generator=generator,
        )
        # Whether to compute exact divergence for log-likelihood
        self.exact_divergence = cfg.exact_divergence
        # Choice of scoring metric
        self.scoring_metric = cfg.scoring_metric
        self.method_name = "cross_laplace"
        
        # Get the fitted Laplace posterior
        self.laplace_posterior = get_laplace_posterior(
            cfg=cfg,
            flow_matching_model=self.flow_matching_model,
            laplace_calib_loader=laplace_calib_loader,
            laplace_path=laplace_path,
        )

    def conditional_sample_with_uncertainty(
        self,
        observation: Dict[str, Tensor]
    ) -> Tuple[Tensor, Tensor]:
        """
        Generates action sequences using the MAP flow matching model, then scores these
        samples under a Laplace-sampled model to obtain epistemic uncertainty.

        Args:
            observation: Info about the environment used to create the conditioning vector for
                the flow matching model. It has to contain the following items:
                {
                "observation.state": (B, n_obs_steps, state_dim)

                "observation.images": (B, n_obs_steps, num_cameras, C, H, W)
                    AND/OR
                "observation.environment_state": (B, environment_dim)
                }

        Returns:
            - sampled_action_seqs: Action sequences drawn from the MAP model.
              Shape: [num_action_seq_samples, horizon, action_dim].
            - uncertainty_scores: Uncertainty scores where a higher value means more
                uncertain. Shape: [num_action_seq_samples,].      
        """
        # Draw flow matching model from the Laplace posterior
        laplace_flow_matching_model = draw_laplace_flow_matching_model(
            laplace_posterior=self.laplace_posterior,
            flow_matching_model=self.flow_matching_model,
            generator=self.generator
        )

        # Encode image features and concatenate them all together along with the state vector
        # to create the flow matching conditioning vectors
        global_cond = self.flow_matching_model.prepare_global_conditioning(observation) # (B, global_cond_dim)
        laplace_global_cond = laplace_flow_matching_model.prepare_global_conditioning(observation)  # (B, global_cond_dim)

        # Adjust shape of conditioning vector
        global_cond = self._prepare_conditioning(global_cond)
        laplace_global_cond = self._prepare_conditioning(laplace_global_cond)

        # Sample noise priors
        noise_samples = torch.randn(
            size=(self.num_action_seq_samples, self.horizon, self.action_dim),
            dtype=self.dtype,
            device=self.device,
            generator=self.generator,
        )

        # Build time grid: include intermediate times if computing velocity norm
        if self.scoring_metric in [
            "intermediate_vel_norm", "terminal_vel_norm", "intermediate_vel_diff"
        ]:
            time_grid = torch.tensor([0.0, 0.92, 0.95, 0.98, 1.0], device=self.device, dtype=self.dtype)
        else:
            time_grid = torch.tensor([0.0, 1.0], device=self.device, dtype=self.dtype)

        # Solve ODE forward from noise to sample action sequences
        ode_states = self.sampling_ode_solver.sample(
            x_0=noise_samples,
            global_cond=global_cond,
            step_size=self.flow_matching_cfg.ode_step_size,
            method=self.flow_matching_cfg.ode_solver_method,
            atol=self.flow_matching_cfg.atol,
            rtol=self.flow_matching_cfg.rtol,
            time_grid=time_grid,
            return_intermediate_states=True,
        )

        # Store sampled action sequences for logging
        sampled_action_seqs = ode_states[-1]
        self.latest_action_candidates = sampled_action_seqs

        # Compute uncertainty based on selected metric
        uncertainty_scores = self.score_sample(
            scoring_metric=self.scoring_metric,
            scorer_velocity_model=laplace_flow_matching_model.unet,
            scorer_global_cond=laplace_global_cond,
            ode_states=ode_states,
            time_grid=time_grid,
            sampler_global_cond=global_cond,
            exact_divergence=self.exact_divergence,
        )
        
        # Store uncertainty scores for logging
        self.latest_uncertainties = uncertainty_scores

        return sampled_action_seqs, uncertainty_scores


class CrossEnsembleSampler(FlowMatchingUncertaintySampler):
    """
    Samples action sequences from a "sampler" flow-matching model and evaluates their
    uncertainty under a separately trained "scorer" flow-matching model. Uncertainty
    can be measured using several different metrics.
    """
    def __init__(
        self,
        flow_matching_cfg: FlowMatchingConfig,
        cfg: CrossEnsembleSamplerConfig,
        sampler_flow_matching_model: nn.Module,
        scorer_flow_matching_model: nn.Module,
        generator: Optional[torch.Generator] = None,
    ):
        """
        Initializes the cross-likelihood ensemble sampler.

        Args:
            cfg: Sampler-specific settings.
            sampler_flow_matching_model: The flow matching network used to generate action sequences.
            scorer_flow_matching_model: Model to score sampled actions.
        """
        super().__init__(
            flow_matching_cfg=flow_matching_cfg,
            velocity_model=sampler_flow_matching_model.unet,
            num_action_seq_samples=cfg.num_action_seq_samples,
            generator=generator,
        )
        # Save models for sampling and scoring
        self.sampler_flow_matching_model = sampler_flow_matching_model
        self.scorer_flow_matching_model = scorer_flow_matching_model
        # Whether to compute exact divergence for log-likelihood
        self.exact_divergence = cfg.exact_divergence
        # Choice of scoring metric
        self.scoring_metric = cfg.scoring_metric
        self.method_name = "cross_ensemble"
        
    def conditional_sample_with_uncertainty(
        self,
        observation: Dict[str, Tensor]
    ) -> Tuple[Tensor, Tensor]:
        """
        Samples candidate action sequences and evaluates uncertainty under separate
        scorer flow matching model using one of several metrics.

        Args:
            observation: Info about the environment used to create the conditioning vector for
                the flow matching model. It has to contain the following items:
                {
                "observation.state": (B, n_obs_steps, state_dim)

                "observation.images": (B, n_obs_steps, num_cameras, C, H, W)
                    AND/OR
                "observation.environment_state": (B, environment_dim)
                }

        Returns:
            - sampled_action_seqs: Action sequences drawn from the sampler model.
                Shape: [num_action_seq_samples, horizon, action_dim].
            - uncertainty_scores: Uncertainty scores where a higher value means more
                uncertain. Shape: [num_action_seq_samples,].       
        """
        # Encode image features and concatenate them all together along with the state vector
        # to create the flow matching conditioning vectors
        global_cond = self.sampler_flow_matching_model.prepare_global_conditioning(observation) # (B, global_cond_dim)
        scorer_global_cond = self.scorer_flow_matching_model.prepare_global_conditioning(observation)  # (B, global_cond_dim)
        
        # Adjust shape of conditioning vectors
        global_cond = self._prepare_conditioning(global_cond)
        scorer_global_cond = self._prepare_conditioning(scorer_global_cond)

        # Sample noise priors
        noise_samples = torch.randn(
            size=(self.num_action_seq_samples, self.horizon, self.action_dim),
            dtype=self.dtype,
            device=self.device,
            generator=self.generator,
        )

        # Build time grid: include intermediate times if computing velocity norm
        if self.scoring_metric in [
            "intermediate_vel_norm", "terminal_vel_norm", "intermediate_vel_diff"
        ]:
            time_grid = torch.tensor([0.0, 0.92, 0.95, 0.98, 1.0], device=self.device, dtype=self.dtype)
        else:
            time_grid = torch.tensor([0.0, 1.0], device=self.device, dtype=self.dtype)

        # Solve ODE forward from noise to sample action sequences
        ode_states = self.sampling_ode_solver.sample(
            x_0=noise_samples,
            global_cond=global_cond,
            step_size=self.flow_matching_cfg.ode_step_size,
            method=self.flow_matching_cfg.ode_solver_method,
            atol=self.flow_matching_cfg.atol,
            rtol=self.flow_matching_cfg.rtol,
            time_grid=time_grid,
            return_intermediate_states=True,
        )

        # Store sampled action sequences for logging
        sampled_action_seqs = ode_states[-1]
        self.latest_action_candidates = sampled_action_seqs

        # Compute uncertainty based on selected metric
        uncertainty_scores = self.score_sample(
            scoring_metric=self.scoring_metric,
            scorer_velocity_model=self.scorer_flow_matching_model.unet,
            scorer_global_cond=scorer_global_cond,
            ode_states=ode_states,
            time_grid=time_grid,
            sampler_global_cond=global_cond,
            exact_divergence=self.exact_divergence,
        )

        # Store uncertainty scores for logging
        self.latest_uncertainties = uncertainty_scores

        return sampled_action_seqs, uncertainty_scores


class ComposedSequenceSampler(FlowMatchingUncertaintySampler):
    """
    Samples action sequences, composes them with a previously executed sequence segment, 
    and evaluates their likelihood under the flow matching model.

    The key idea is that if the composed sequences have a high likelihood, then the model
    successfully anticipated what is likely to happen next. This implies a good internal model 
    of the environment.
    """
    def __init__(
        self,
        flow_matching_cfg: FlowMatchingConfig,
        cfg: ComposedSequenceSamplerConfig,
        velocity_model: nn.Module,
        generator: Optional[torch.Generator] = None,
    ):
        """
        Args:
            cfg: Sampler-specific settings.
        """
        super().__init__(
            flow_matching_cfg=flow_matching_cfg,
            velocity_model=velocity_model,
            num_action_seq_samples=cfg.num_action_seq_samples,
            generator=generator,
        )
        # Whether to compute exact divergence for log-likelihood
        self.exact_divergence = cfg.exact_divergence
        # Choice of scoring metric
        self.scoring_metric = cfg.scoring_metric
        if self.scoring_metric not in ("likelihood", "terminal_vel_norm"):
            raise ValueError(
                f"Unsupported scoring_metric '{self.scoring_metric}'. "
                "Expected one of: 'likelihood', 'terminal_vel_norm'."
            )
        # Store the action sequence and conditioning vector from the previous action
        # sequence generation
        self.prev_action_sequence = None
        self.prev_global_cond = None
        self.method_name = "composed_sequence"

    def conditional_sample_with_uncertainty(
        self,
        global_cond: Tensor,
    ) -> Tuple[Tensor, Tensor]:
        """
        Samples `num_action_seq_samples` many new action sequences and computes
        uncertainty scores by composing them with a previous action sequence and evaluating
        their negative log-likelihoods under the flow model.

        Args:
            global_cond: Single conditioning feature vector for the velocity
                model. Shape: [cond_dim,] or [1, cond_dim].

        Returns:
            - Action sequence samples. Shape: [num_action_seq_samples, horizon, action_dim].
            - Uncertainty scores given by negative log-likelihood of composed trajectories.
              Shape: [num_action_seq_samples,]
        """
        # Adjust shape of conditioning vector
        global_cond = self._prepare_conditioning(global_cond)
        if self.prev_global_cond is not None:
            self.prev_global_cond = self._prepare_conditioning(self.prev_global_cond)

        # Sample noise priors
        noise_samples = torch.randn(
            size=(self.num_action_seq_samples, self.horizon, self.action_dim),
            dtype=self.dtype,
            device=self.device,
            generator=self.generator,
        )

        # Solve ODE forward from noise to sample action sequences
        new_action_seqs = self.sampling_ode_solver.sample(
            x_0=noise_samples,
            global_cond=global_cond,
            step_size=self.flow_matching_cfg.ode_step_size,
            method=self.flow_matching_cfg.ode_solver_method,
            atol=self.flow_matching_cfg.atol,
            rtol=self.flow_matching_cfg.rtol,
        )
        # Store sampled action sequences for logging
        self.latest_action_candidates = new_action_seqs

        # If no previous trajectory is stored, return placeholder uncertainties
        if self.prev_action_sequence is None:
            uncertainty_scores = torch.full(
                (self.num_action_seq_samples,),
                float('-inf'),
                dtype=self.dtype,
                device=self.device
            )
            # Store computed uncertainty scores for logging
            self.latest_uncertainties = uncertainty_scores

            return new_action_seqs, uncertainty_scores

        # Indices where to split and recompose the trajectory
        prev_action_seq_end = self.flow_matching_cfg.n_obs_steps - 1 + self.flow_matching_cfg.n_action_steps
        new_action_seqs_start = self.flow_matching_cfg.n_obs_steps - 1
        new_action_seqs_end = new_action_seqs_start + (self.horizon - prev_action_seq_end)
        
        # Repeat previous prefix to match batch dimension
        prev_action_sequence_duplicated = self.prev_action_sequence.expand(self.num_action_seq_samples, -1, -1)
        
        # Compose full action sequences from stored prefix and newly sampled action sequences
        composed_action_seqs = torch.cat([
            prev_action_sequence_duplicated[:, :prev_action_seq_end, :],
            new_action_seqs[:, new_action_seqs_start:new_action_seqs_end, :]
        ], dim=1)

        # Build time grid: include intermediate times if computing velocity norm
        if self.scoring_metric == "terminal_vel_norm":
            time_grid = torch.tensor([0.0, 0.92, 0.95, 0.98, 1.0], device=self.device, dtype=self.dtype)
        elif self.scoring_metric == "likelihood":
            time_grid = torch.tensor([0.0, 1.0], device=self.device, dtype=self.dtype)

        # Compute uncertainty based on selected metric
        uncertainty_scores = self.score_sample(
            scoring_metric=self.scoring_metric,
            scorer_velocity_model=self.velocity_model,
            scorer_global_cond=global_cond,
            ode_states=composed_action_seqs.unsqueeze(0),
            time_grid=time_grid,
            sampler_global_cond=global_cond,
            exact_divergence=self.exact_divergence,
        )

        # Store computed uncertainty scores for logging
        self.latest_uncertainties = uncertainty_scores

        return new_action_seqs, uncertainty_scores
    

class LikelihoodSampler(FlowMatchingUncertaintySampler):
    """
    Samples multiple action sequences x_1 and use their negative log-likelihoods
    -log(p_1(x_1)) under the flow matching mode as an uncertainty score.
    Smaller likelihood values p_1(x_1) correspond to a more uniform target
    distribution p_1(x_1) and therefore imply a greater uncertainty.
    """
    def __init__(
        self,
        flow_matching_cfg: FlowMatchingConfig,
        cfg: LikSamplerConfig,
        velocity_model: nn.Module,
        generator: Optional[torch.Generator] = None,
    ):
        """
        Args:
            cfg: Sampler-specific settings.
        """
        super().__init__(
            flow_matching_cfg=flow_matching_cfg,
            velocity_model=velocity_model,
            num_action_seq_samples=cfg.num_action_seq_samples,
            generator=generator,
        )
        self.exact_divergence = cfg.exact_divergence
        self.method_name = "likelihood"
    
    def conditional_sample_with_uncertainty(
        self,
        global_cond: Tensor,
    ) -> Tuple[Tensor, Tensor]:
        """
        Samples `num_action_seq_samples` many action sequences x_1 and computes their
        log-likelihoods log(p_1(x_1)) via solving the combined flow matching ODE in
        forward direction. Then uses negative log-liklihoods -log(p_1(x_1)) as uncertainty
        scores such that a lower likelihood implies a larger uncertainty. 

        Args:
            global_cond: Single conditioning feature vector for the velocity
                model. Shape: [cond_dim,] or [1, cond_dim].

        Returns:
            - Action sequences samples. Shape: [num_action_seq_samples, horizon, action_dim].
            - Uncertainty scores given by negative log-likelihood of the action sequnece
              samples. Shape: [num_action_seq_samples,]
        """
        if global_cond.dim() == 1: # shape = (cond_dim,)
            global_cond = global_cond.unsqueeze(0)                                   # (1, cond_dim)
            global_cond = global_cond.repeat(self.num_action_seq_samples, 1)
        elif global_cond.dim() == 2 and global_cond.size(0) == 1: # shape = (1, cond_dim)
            global_cond = global_cond.repeat(self.num_action_seq_samples, 1)
        else:
            raise ValueError(
                f"Expected global_cond to contain exactly one feature vector "
                f"(shape (cond_dim,) or (1,cond_dim)), but got shape {tuple(global_cond.shape)}"
            )

        # Sample noise priors.
        noise_sample = torch.randn(
            size=(self.num_action_seq_samples, self.horizon, self.action_dim),
            dtype=self.dtype,
            device=self.device,
            generator=self.generator,
        )

        # Noise distribution is an isotropic Gaussian.
        gaussian_log_density = Independent(
            Normal(
                loc = torch.zeros(self.horizon, self.action_dim, device=self.device),
                scale = torch.ones(self.horizon, self.action_dim, device=self.device),
            ),
            reinterpreted_batch_ndims=2
        ).log_prob
        
        # Solve combined flow matching ODE in forward direction to sample
        # action sequences x_1 and compute their log-likelihoods log(p_1(x_1)).
        action_seqs, log_probs = self.sampling_ode_solver.sample_with_log_likelihood(
            x_init=noise_sample,
            time_grid=torch.tensor([0.0, 1.0], device=self.device, dtype=self.dtype),
            global_cond=global_cond,
            log_p_0 = gaussian_log_density,
            method=self.flow_matching_cfg.ode_solver_method,
            step_size=self.flow_matching_cfg.ode_step_size,
            atol=self.flow_matching_cfg.atol,
            rtol=self.flow_matching_cfg.rtol,
            exact_divergence=self.exact_divergence,
            generator=self.generator,
        )

        # Uncertainty score is given by -log(p_1(x_1))
        uncertainty_scores = -log_probs

        # Store sampled action sequences and uncertainty scores for logging
        self.latest_action_candidates = action_seqs
        self.latest_uncertainties = uncertainty_scores

        return action_seqs, uncertainty_scores

    
class EpsilonBallSampler(FlowMatchingUncertaintySampler):
    """
    Samples action sequences and measures how an epsilon-ball around each initial noise
    sample expands through the flow.
    """
    def __init__(
        self,
        flow_matching_cfg: FlowMatchingConfig,
        cfg: EpsilonBallSamplerConfig,
        velocity_model: nn.Module,
        generator: Optional[torch.Generator] = None,
    ):
        """
        Args:
            cfg: Sampler-specific settings.
        """
        super().__init__(
            flow_matching_cfg=flow_matching_cfg,
            velocity_model=velocity_model,
            num_action_seq_samples=cfg.num_action_seq_samples,
            generator=generator,
        )
        self.epsilon = cfg.epsilon
        self.num_eps_ball_samples = cfg.num_eps_ball_samples
        self.method_name = "epsilon_ball"
    
    def conditional_sample_with_uncertainty(
        self,
        global_cond: Tensor,
    ) -> Tuple[Tensor, Tensor]:
        """
        Samples `num_action_seq_samples` many action sequences and computes their
        uncertainty scores by estimating how epsilon-ball perturbations around their
        initial noise samples expand through the flow model.

        To compute the uncertainty scores, it draws num_samples points uniformly in an
        epsilon-ball around each initial noise sample, runs the ODE solver from each of
        these epsilon ball samples, and computes the ratio of the average output to the
        average input divergence.

        Args:
            global_cond: Single conditioning feature vector for the velocity
                model. Shape: [cond_dim,] or [1, cond_dim].

        Returns:
            - Action sequences samples. Shape: [num_action_seq_samples, horizon, action_dim].
            - Uncertainty scores given by epsilon-ball expansion factors.
              Shape: [num_action_seq_samples,]
        """
        if global_cond.dim() == 1: # shape = (cond_dim,)
            global_cond = global_cond.unsqueeze(0)     # (1, cond_dim)
        elif global_cond.dim() == 2 and global_cond.size(0) == 1: # shape = (1, cond_dim)
            pass
        else:
            raise ValueError(
                f"Expected global_cond to contain exactly one feature vector "
                f"(shape (cond_dim,) or (1,cond_dim)), but got shape {tuple(global_cond.shape)}"
            )

        # Sample noise priors.
        noise_samples = torch.randn(
            size=(self.num_action_seq_samples, self.horizon, self.action_dim),
            dtype=self.dtype,
            device=self.device,
            generator=self.generator,
        )

        # Initialize tensors to store the action sequences and expansion factors.
        action_sequences = torch.zeros_like(noise_samples)
        expansion_factors = torch.zeros(
            size=(self.num_action_seq_samples,),
            dtype=self.dtype,
            device=self.device,
        )
        
        # TODO: Remove for loop and parallelize code
        # Generate an action sequence and uncertainty score for each of the `num_action_seq_samples`
        # noise samples.
        for action_seq_idx, noise_sample in enumerate(noise_samples):
            # Sample num_samples directions on the unit sphere.
            directions = torch.randn(
                self.num_eps_ball_samples,
                self.horizon,
                self.action_dim,
                device=self.device,
                dtype=self.dtype,
                generator=self.generator,
            )
            
            # Normalize each direction to unit length.
            norms = directions.view(self.num_eps_ball_samples, -1).norm(dim=1, keepdim=True)
            directions = directions / norms.view(self.num_eps_ball_samples, 1, 1)

            # Sample random radii so the points fill the ball uniformly.
            radii = torch.rand(
                self.num_eps_ball_samples,
                device=self.device,
                dtype=self.dtype,
                generator=self.generator,
            ) ** (1.0/(self.horizon*self.action_dim))
            radii = radii.view(self.num_eps_ball_samples, 1, 1) * self.epsilon                         # (N,1,1)
            
            # Compute average distance in noise space
            avg_noise_dist = radii.mean()

            # Get the samples in an epsilon-ball around the original noise sample.
            epsilon_samples = noise_sample + radii * directions   

            # Based on the center noise sample of the epsilon-ball use the velocity model
            # and an ODE solver to predict an action sequence sample from the target distribution.
            reference_action_sequence = self.sampling_ode_solver.sample(
                x_0=noise_sample.unsqueeze(0),
                global_cond=global_cond,
                step_size=self.flow_matching_cfg.ode_step_size,
                method=self.flow_matching_cfg.ode_solver_method,
                atol=self.flow_matching_cfg.atol,
                rtol=self.flow_matching_cfg.rtol,
            )
            action_sequences[action_seq_idx] = reference_action_sequence

            # Solve flow matching ODE for samples in epsilon-ball around the initial noise sample.
            perturbed_action_sequences = self.sampling_ode_solver.sample(
                x_0=epsilon_samples,
                global_cond=global_cond.repeat(self.num_eps_ball_samples, 1),
                step_size=self.flow_matching_cfg.ode_step_size,
                method=self.flow_matching_cfg.ode_solver_method,
                atol=self.flow_matching_cfg.atol,
                rtol=self.flow_matching_cfg.rtol,
            )

            # Compute average distance in action space.
            action_sequence_dist = (perturbed_action_sequences - reference_action_sequence).norm(dim=1) 
            avg_action_sequence_dist = action_sequence_dist.mean()

            # Compute the factor by which the average distance of the epsilon-ball samples increases
            # from the noise to the action space.
            expansion_factor = avg_action_sequence_dist / avg_noise_dist

            expansion_factors[action_seq_idx] = expansion_factor

            # Store sampled action sequences and uncertainty scores for logging
            self.latest_action_candidates = action_sequences
            self.latest_uncertainties = expansion_factors
            
        return action_sequences, expansion_factors
        