from abc import ABC, abstractmethod
from typing import Any, Optional

import torch
from torch import Tensor
from torch.distributions import Independent, Normal

from lerobot.common.policies.flow_matching.conditional_probability_path import (
    OTCondProbPath,
    VPDiffusionCondProbPath,
)
from lerobot.common.policies.flow_matching.modelling_flow_matching import FlowMatchingConditionalUnet1d
from lerobot.common.policies.flow_matching.ode_solver import ADAPTIVE_SOLVERS, FIXED_STEP_SOLVERS, ODESolver
from lerobot.common.policies.utils import get_device_from_parameters, get_dtype_from_parameters

from .base_sampler import FlowMatchingUncertaintySampler
from .configuration_uncertainty_sampler import ScoringMetricConfig


class FlowMatchingUncertaintyMetric(ABC):
    """Abstract base for uncertainty metrics that score sampled action sequences."""
    name: str = "base"

    @abstractmethod
    def __call__(
        self,
        scorer_velocity_model: FlowMatchingConditionalUnet1d,
        scorer_global_cond: Tensor,
        ode_states: Tensor,
        **kwargs: Any,
    ) -> Tensor:
        """
        Compute an uncertainty score for a batch of action sequence samples
        generated by the sampler flow matching model using a scorer flow matching
        model.
        Args:
            scorer_velocity_model: Flow matching velocity model to compute the velocities
                field for scoring.
            scorer_global_cond: Conditioning vector used for the scorer model.
                Shape: (batch_size, cond_dim).
            ode_states: States produced by the forward ODE solver. Shape: (num_eval_points,
                batch_size, horizon, action_dim).

        Returns:
            Uncertainty scores per sample where larger values indicate higher uncertainty.
            Shape: (batch_size,).
        """
        pass


class TerminalVelNorm(FlowMatchingUncertaintyMetric):
    """
    Uncertainty score based on the average L2 norm of scorer velocities at sampled sequence.
    """
    name: str = "terminal_vel_norm"

    def __init__(self, config: ScoringMetricConfig):
        """
        Args:
            config: Scoring metric settings.
        """
        self.velocity_eval_times = config.velocity_eval_times

    def __call__(
        self,
        scorer_velocity_model: FlowMatchingConditionalUnet1d,
        scorer_global_cond: Tensor,
        ode_states: Tensor,
        **_: Any
    ) -> Tensor:
        """
        Evaluate the scorer velocity only on the final sampled action sequence
        but at several evaluation times and compute the average L2 norm.
        """
        device = get_device_from_parameters(scorer_velocity_model)
        dtype = get_dtype_from_parameters(scorer_velocity_model)
        # The sampled action sequence corresponds to the final state of the ODE
        sampled_action_seq = ode_states[-1]
        # Evaluate velocity on the final sampled sequence
        terminal_vel_norms: list[float] = []
        for time in self.velocity_eval_times:
            time_batch = torch.full(
                (sampled_action_seq.shape[0],), time, device=device, dtype=dtype
            )
            velocity = scorer_velocity_model(
                sampled_action_seq,
                time_batch,
                scorer_global_cond,
            )
            terminal_vel_norms.append(torch.norm(velocity, dim=(1, 2)))

        # Use average velocity norm as uncertainty score 
        return torch.stack(terminal_vel_norms, dim=0).mean(dim=0)


class ModeDistance(FlowMatchingUncertaintyMetric):
    """Uncertainty score based on weighted velocity magnitude as a proxy for distance from next mode."""
    name: str = "mode_distance"

    def __init__(self, config: ScoringMetricConfig):
        """
        Args:
            config: Scoring metric settings.
        """
        self.velocity_eval_times = config.velocity_eval_times

    def __call__(
        self,
        scorer_velocity_model: FlowMatchingConditionalUnet1d,
        scorer_global_cond: Tensor,
        ode_states: Tensor,
        **_: Any,
    ) -> Tensor:
        """
        Proxy "distance-from-mode" score computed by averaging (1 - t) * ‖v(t)‖
        of the scorer's velocity at the final sampled action sequence across the
        specified evaluation times.
        """
        device = get_device_from_parameters(scorer_velocity_model)
        dtype = get_dtype_from_parameters(scorer_velocity_model)
        # The sampled action sequence corresponds to the final state of the ODE
        sampled_action_seq = ode_states[-1]
        distances: list[float] = []
        # Loop over each time in [0, 1) at which we want to probe the velocity field
        for time in self.velocity_eval_times:
            time_batch = torch.full(
                (sampled_action_seq.shape[0],), time, device=device, dtype=dtype
            )
            # Query the scorer’s velocity field at the sampled action sequence and this time
            velocity = scorer_velocity_model(
                sampled_action_seq,
                time_batch,
                scorer_global_cond,
            )
            velocity_norm = torch.norm(velocity, dim=(1, 2))
            # Scale by (1 - time) as a simple proxy for “distance from the mode”
            # (i.e. how far a particle would still travel under constant velocity)
            distance = (1 - time) * velocity_norm
            distances.append(distance)

        return torch.stack(distances, dim=0).mean(dim=0)


class InterVelDiff(FlowMatchingUncertaintyMetric):
    """
    Uncertainty metric based on the average discrepancy between sampler and scorer 
    velocity fields across intermediate ODE states.
    """
    name: str = "inter_vel_diff"

    def __init__(self, config: ScoringMetricConfig, uncertainty_sampler: FlowMatchingUncertaintySampler):
        """
        Args:
            config: Scoring metric settings.
        """
        self.velocity_eval_times = config.velocity_eval_times
        self.device = uncertainty_sampler.device
        self.dtype = uncertainty_sampler.dtype
        self.sampler_velocity_model = uncertainty_sampler.velocity_model
        self.sampler_ode_solver = uncertainty_sampler.sampling_ode_solver
        self.sampling_time_grid = uncertainty_sampler.sampling_time_grid
        self.cond_vf_type = uncertainty_sampler.flow_matching_cfg.cond_vf_type
        if self.cond_vf_type == "vp":
            self.cond_prob_path = VPDiffusionCondProbPath(
                beta_min=uncertainty_sampler.flow_matching_cfg.beta_min,
                beta_max=uncertainty_sampler.flow_matching_cfg.beta_max,
            )
        else:
            self.cond_prob_path = OTCondProbPath()
    
    def _get_scaling_factor(self, t: Tensor) -> Tensor:
        """
        Scale factor used when computing the intermediate-velocity-difference uncertainty metric.
        """
        if self.cond_vf_type == "vp":
            return (2 / self.cond_prob_path.get_beta(t))
        elif self.cond_vf_type == "ot":
            return t
        else:
            raise ValueError(
                "No intermediate velocity difference factor provided for conditional " \
                f"VF type: {self.cond_vf_type}."
            )

    def __call__(
        self,
        scorer_velocity_model: FlowMatchingConditionalUnet1d,
        scorer_global_cond: Tensor,
        ode_states: Tensor,
        sampler_global_cond: Tensor,
        **_: Any,
    ) -> Tensor:
        """
        At each intermediate ODE state compare the sampler and score velocities,
        ||v_sampler(x_t) - v_scorer(x_t)||, and average them.

        Args:
            velocity_eval_times: Times at which the velocity model is evaluated on the intermediate
                ODE states.
            sampler_global_cond: Conditioning vector of the sampler model. Shape: (batch_size, cond_dim).
        """
        # Select the ODE states that correspond to the velocity evaluation times
        selected_ode_states, selected_grid_times = self.sampler_ode_solver.select_ode_states(
            time_grid=self.sampling_time_grid,
            ode_states=ode_states,
            requested_times=torch.tensor(self.velocity_eval_times, device=self.device, dtype=self.dtype)
        )
        
        # Evaluate difference between sampler and scorer velocity field at each
        # intermediate time point
        batch_size = ode_states[-1].shape[0]
        inter_vel_diff_score: Tensor = torch.zeros(batch_size, device=self.device, dtype=self.dtype)
        for idx, (time, inter_state) in enumerate(zip(selected_grid_times, selected_ode_states, strict=False)):
            # Determine dt: difference to next time or to 1.0 for last step
            dt = selected_grid_times[idx + 1] - time if idx < len(selected_grid_times) - 1 else 1.0 - time
        
            time_batch = torch.full(
                (batch_size,), time, device=self.device, dtype=self.dtype
            )
            sampler_velocity = self.sampler_velocity_model(
                inter_state,
                time_batch,
                sampler_global_cond,
            )
            scorer_velocity = scorer_velocity_model(
                inter_state,
                time_batch,
                scorer_global_cond,
            )
            # L2 norm across time and action dims gives magnitude of velocity difference
            velocity_difference = torch.norm(sampler_velocity - scorer_velocity, dim=(1, 2)) ** 2
            
            # Scale velocity difference by factor that depends on conditional vector field type
            inter_vel_diff_score += (
                self._get_scaling_factor(time)
                * velocity_difference
                * dt
            )
        
        return inter_vel_diff_score
    
class Likelihood(FlowMatchingUncertaintyMetric):
    """
    Uncertainty metric that scores samples by their negative log-likelihood under the scorer model. 
    Uses an ODE solver to estimate likelihood along a reverse-time trajectory.
    """
    name: str = "likelihood"

    def __init__(self, config: ScoringMetricConfig, uncertainty_sampler: FlowMatchingUncertaintySampler):           
        """
        Args:
            config: Scoring metric settings.
        """
        self.device = uncertainty_sampler.device
        self.dtype = uncertainty_sampler.dtype
        # Noise distribution is an isotropic Gaussian
        horizon = uncertainty_sampler.horizon
        action_dim = uncertainty_sampler.action_dim
        self.gaussian_log_density = Independent(
            Normal(
                loc = torch.zeros(horizon, action_dim, device=self.device, dtype=self.dtype),
                scale = torch.ones(horizon, action_dim, device=self.device, dtype=self.dtype),
            ),
            reinterpreted_batch_ndims=2
        ).log_prob

        # Configuration of ODE solver to score samples via a likelihood estimate
        self.lik_ode_solver_cfg = config.likelihood_ode_solver_cfg

        # Build time grid for likelihood estimation absed on ODE solver method
        self.lik_estimation_time_grid = self._get_lik_estimation_time_grid()        

    def _get_lik_estimation_time_grid(self) -> Tensor:
        """
        Build time grid to estimate likelihood according to ODE solver method.

        For a fixed step solver the time grid consists of a fine segment of 10 points evenly
        spaced from 1.0 up to 0.93 and a coarse segment of 10 points evenly spaced from 0.9 up to 0.0.

        Returns:
            A 1D time grid.
        """
        if self.lik_ode_solver_cfg.method in FIXED_STEP_SOLVERS:
            fine = torch.linspace(1.0, 0.93, steps=10, device=self.device, dtype=self.dtype)
            coarse = torch.linspace(0.9, 0.0,  steps=10, device=self.device, dtype=self.dtype)
            return torch.cat((fine, coarse))
        elif self.lik_ode_solver_cfg.method in ADAPTIVE_SOLVERS:
            lik_estimation_time_grid = torch.tensor([1.0, 0.0], device=self.device, dtype=self.dtype)
        else:
            raise ValueError(
                f"Unknown ODE solver method {self.lik_ode_solver_cfg.method}. "
                f"Expected one of {sorted(FIXED_STEP_SOLVERS | ADAPTIVE_SOLVERS)}."
            )

        return lik_estimation_time_grid

    def __call__(
        self,
        scorer_velocity_model: FlowMatchingConditionalUnet1d,
        scorer_global_cond: Tensor,
        ode_states: Tensor,
        generator: Optional[torch.Generator] = None,
        **_: Any,
    ) -> Tensor:
        """
        Run a reverse-time ODE under the scorer model to compute the log-likelihood of the 
        final sample; the score is the negative log-likelihood.
        """
        # Compute log-likelihood of sampled action sequences in scorer model    
        scoring_ode_solver = ODESolver(scorer_velocity_model)
        _, log_probs = scoring_ode_solver.sample_with_log_likelihood(
            x_init=ode_states[-1],
            time_grid=self.lik_estimation_time_grid,
            global_cond=scorer_global_cond,
            log_p_0=self.gaussian_log_density,
            method=self.lik_ode_solver_cfg.method,
            atol=self.lik_ode_solver_cfg.atol,
            rtol=self.lik_ode_solver_cfg.rtol,
            exact_divergence=self.lik_ode_solver_cfg.exact_divergence,
            generator=generator,
        )

        # Use negative log-likelihood as uncertainty score
        return -log_probs